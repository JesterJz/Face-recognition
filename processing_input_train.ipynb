{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = './dataset/train_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(dir):\n",
    "\n",
    "    train_data = []\n",
    "    dict = []\n",
    "    count = 0\n",
    "    for whatever in os.listdir(dir):\n",
    "\n",
    "        temp = [0]*len(os.listdir(dir))\n",
    "        temp[count] = 1\n",
    "        count += 1\n",
    "        dict.append((whatever, temp))\n",
    "\n",
    "        whatever_path = os.path.join(dir, whatever)\n",
    "        lst_filename_path = []\n",
    "        for filename in os.listdir(whatever_path):\n",
    "            filename_path = os.path.join(whatever_path, filename)\n",
    "            img = np.array(Image.open(filename_path))\n",
    "            lst_filename_path.append((img, temp))\n",
    "\n",
    "        train_data.extend(lst_filename_path)\n",
    "\n",
    "    return train_data, dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dict = getdata(DATA)\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "xtrain = np.array([x[0] for i, x in enumerate(train_data)])\n",
    "ytrain = np.array([x[1] for i, x in enumerate(train_data)])\n",
    "# print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Dropout(0.15),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Dropout(0.18),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1000, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model_train.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "#model_train.summary()\n",
    "\n",
    "model_train.fit(xtrain, ytrain, epochs=10)\n",
    "\n",
    "model_train.save('./model/model_test.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
